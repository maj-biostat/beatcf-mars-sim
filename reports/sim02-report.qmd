---
title: BEAT CF MARS
subtitle: Simulation Report
description: |
    Three-arm Bayesian adaptive trial nested within BEAT-CF platform evaluating antibiotic-sparing strategies for managing pulmonary exacerbations
date: last-modified
date-format: "D MMMM YYYY"
author: 
  - name: Mark Jones
    id: mj
    email: mark.jones1@sydney.edu.au
version: 0.1
sponsor: "University of Sydney, NSW, Australia"
protocol-number: todo
registration: todo
hrec: todo
ci1: Tom Snelling
editor: source
bibliography: ../etc/refs.bib
csl: ../etc/elsevier-harvard.csl
# number-sections required otherwise section refs will not render 
number-sections: true
toc: true
toc-depth: 3
format:
  pdf: 
    pdf-engine: xelatex
    keep-tex: true
    documentclass: scrreprt
    papersize: a4
    fontsize: 12pt
    mainfont: Libertinus Serif
    sansfont: Libertinus Sans
    monofont: Libertinus Mono
    mathfont: Libertinus Math
    linestretch: 1.25
    template-partials: 
      - "../_extensions/partials/before-body.tex"
    include-in-header:
      text: |
       \usepackage{physics}
       \setkomafont{chapter}{\fontsize{16}{18}\selectfont}
       \setkomafont{section}{\fontsize{14}{16}\selectfont}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE
)
```

```{r}
#| echo: false

# uml digs
suppressPackageStartupMessages(library(nomnoml))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(data.table))
suppressPackageStartupMessages(library(qs))
suppressPackageStartupMessages(library(git2r))
suppressPackageStartupMessages(suppressWarnings(library(gt)))
suppressPackageStartupMessages(library(ggh4x))
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(scales))
suppressPackageStartupMessages(library(patchwork))
suppressPackageStartupMessages(library(pbapply))


toks <- unlist(tstrsplit(getwd(), "/")) 
if(toks[length(toks)] == "beatcf-mars-sim"){
  prefix_cfg <- "./etc/sim02/"
  prefix_stan <- "./stan"
  prefix_fig <- "./fig"
  prefix_data <- "./data"
  prefix_r <- "./r"
} else {
  prefix_cfg <- "../etc/sim02/"
  prefix_stan <- "../stan"
  prefix_fig <- "../fig"
  prefix_data <- "../data"
  prefix_r <- "../r"
}


source(paste0(prefix_r, "/data.R"))

# Reference design

sim_lab <- "sim00-01"

flist <- list.files(paste0(prefix_data, "/", sim_lab), pattern = "sim00")
toks <- list()
l0 <- list()
i <- 1

for(i in 1:length(flist)){

  l0[[i]] <- qs::qread(file.path(paste0(prefix_data, "/", sim_lab), flist[i]))
}



# Each input file corresponds to the results from a single simulation
# scenario/configuration.
# Load all the files into a single list.

# files of interest
sim_lab <- "sim02-02"

flist <- list.files(paste0(prefix_data, "/", sim_lab), pattern = "sim02")
toks <- list()
l <- list()
i <- 1

for(i in 1:length(flist)){

  l[[i]] <- qs::qread(file.path(paste0(prefix_data, "/", sim_lab), flist[i]))
  toks[[i]] <-  unlist(tstrsplit(flist[i], "[-.]"))
}

N_sims <- l[[1]]$cfg$nsim

N_example_sims <- 7
```

{{< pagebreak >}}

::: summary
|     |        |
|:----|:------------|
|Study title:  |  BEAT-CF MARS |
|Reference intervention: |  Standard airway clearance therapy at least twice per day for 14 days, plus 14 days of oral antibiotics commencing as soon as practicable (and â‰¥ 72 hours and < 7 days) after onset of new or acute worsening of cough. |   
|Intervention: | (1) Deferred antibiotic strategy (2) Early discontinuation antibiotic strategy. |   
|Outcome: | ppFev1 at 12 months |   
|Study design:  |   Bayesian adaptive trial with early stopping rules | 
|Sponsor:  |    University of Sydney, NSW, Australia | 
Protocol: |  todo |
|Registration:  |    todo | 
|HREC:  |   todo | 
|Study date of first consent:  |   todo | 
|Principal coordinating investigators:  |   Tom Snelling | 
:::

<!-- 
Note that the above relies on the pandoc extension implemented in the lua file 
in the etc directory. It additionally relies on the presence of a custom style
in word called study summary. It will currently only work for word (because I
cannot be bothered to implement it in anything else at the moment).
-->


{{< pagebreak >}}

# Version history {.unlisted .unnumbered}

| Version    |   Date     | Change    |   Reason     |
|:----|:------------|:----|:------------|
| 0.1 | 2025-08-27 | First version | N/A |


{{< pagebreak >}}



# Introduction

This report documents the simulation approach and results for the operating characteristics for the BEAT-CF MARS study.
The report is an operational document that will be updated, as necessary, over the course of the study.
It should be read in conjunction with the relevant version of the statistical analysis plan.

We provide the data generation assumptions, modelling approaches, scenarios and results that were used to explore the design.

These results are based on simulation `r sim_lab` with `r N_sims` simulated trials run per scenario.

# Design overview

BEAT-CF-MARs is a non-inferiority study that adopts a pre/post design where lung function is measured under each of the treatment strategies and control group both at baseline and after having received 12 months of the assigned intervention.

Participants are randomised with equal allocation to one of the three strategies at enrolment and this allocation is assumed to hold over the following 12 month period, i.e. whenever an exacerbation occurs the treatment regime is assumed to be that which was assigned.

The outcome (ppFEV1) is measured at baseline and 12 months followup on individual participants and we examine the difference the difference in mean lung function at follow up.

The design includes adaptation that permits early stopping of treatment arms for non-inferiority or inferiority.
The control arm of standard of care remains the reference arm throughout.

## Alternatives

Several revisions to the design might be made on what is presented here.
For example:

1. Repeat the data collection step a multiple times on each participant at baseline and followup, e.g. one reading per day over three days or three readings in one-day
2. Attempt to account for the number/frequency/severity of exacerbations to improve precision
3. Follow up at multiple timepoints rather than just pre/post
4. Re-randomisation participants to alternative treatments over the 12 month period; patients would be randomised on each exacerbation
5. Some level of stratification may be considered
6. Alternative followup timepoint
7. ...

# Data generation {#sec-data-generation}

Data is generated based on subject matter expertise and while necessarily a simplification of reality, it aims to capture the aspects that are essential to the design.
The distributional assumptions of each data component follows.

The outcome measure, ppFEV1 (percent predicted forced expiratory volume in one second) characterises lung function on how well a person can exhale air in one second compared to what is expected for someone of their age, height, sex, and race.
When the lungs are working properly, the values should be close to 100%.

The participant characteristics and their outcome variables are generated as cohorts prior to each analysis such that the data accrues sequentially.
As the trial progresses, decisions may be made which lead to early stopping of treatment arms.

We simulate ppFEV1 at baseline and 12 months follow up, assuming the population arises from a normal distribution with with a mean of `r l[[1]]$cfg$b_0` and a 1% decline (in absolute terms) per year.
Missingness is assumed to follow MCAR across all treatment groups with a `r l[[1]]$cfg$pr_ymis` missing probability.

Patient level heterogeneity is assumed to be multivariate normal with standard deviations of `r l[[1]]$cfg$u_s0` and `r l[[1]]$cfg$u_s1` on the intercept (baseline) and slope (followup increment) respectively and with `r l[[1]]$cfg$u_rho` correlation between them.
Treatment arms are assumed to have a range of small deviations at the 12 month followup relative to the standard of care group (see @sec-scenarios).
The residual standard deviation is assumed to be `r l[[1]]$cfg$b_se`.

The linear combination of terms used to simulate the outcome variable at baseline and followup is:

$$
\begin{aligned}
\mu_i &=  (\beta_0 + u_{i0}) + (\beta_1 + u_{i1}) \times \text{post}_i + \\
  &\quad \gamma_1 \times  \text{defer}_i \times  \text{post}_i +    
         \gamma_2 \times  \text{discontinue}_i \times  \text{post}_i
\end{aligned}
$$

where 

+ $\beta_0$ and $\beta_1$ are the population intercept and slope
+ $u_{i0}$ and $u_{i1}$ are the participant level offset from the intercept and slope, normally distribution with zero centres and covariance as discussed above
+ $\gamma_1$ and $\gamma_2$ are the effects of the deferred and discontinued treatment at followup

Taking *post*, *defer* and *discontinue* as indicator variables, we then simulate a value for the observed outcome under a normal model with mean $\mu_i$ and standard error $\sigma_\epsilon$.

Treatment status was allocated 1:1:1, which is updated to 1:1 if a decision threshold is reached for non-inferiority or inferiority.
The initial standard of care remains the reference group throughout and the trial stops once all questions are resolved or the maximum sample size of `r sum(l[[1]]$cfg$N)` reached.

Accrual is assumed to follow a non-homogenous poisson process with linear ramp up over `r l[[1]]$cfg$ramp_up_days` days with around `r l[[1]]$cfg$pt_per_day` enrolments per day.
Follow up is assumed to occur within a window of `r l[[1]]$cfg$fu_days_lwr` to `r l[[1]]$cfg$fu_days_upr` days.


# Modelling {#sec-modelling}

## Overview

The interim analyses are based on the available complete baseline and followup data.
For example, out of 400 enrolments, there might be 260 that have reached their follow up at the time when the 400th patient is enrolled and thus 260 would enter into the interim analysis.
The final analysis is run after followup is complete on all participants.

The model is a bivariate autoregressive form that accounts for the within participant correlation between ppFEV1 at the baseline and followup by the inclusion of the observed baseline value for ppFEV1.
Specifically, the outcome is modelled using a linear model that regresses the follow up measure for ppFEV1 on the baseline measure and treatment assignment (i.e. ANCOVA).
The groups level means and group differences in means are computed via a g-computation step.
The analysis is conducted for complete cases (missing values are not imputed).

The model form is:

$$
\begin{aligned}
y_{\text{post}} &\sim \text{Normal}(\mu, \sigma_e) \\
\mu &=  \alpha + \beta \times y_{\text{pre}} + \gamma_1 \times \text{defer}_i + \gamma_2 \times \text{discontinue}_i  \\
\end{aligned}
$$

where $y_{\text{post}}$ is a normally distributed random variable for the ppFEV1 at 12 months and $y_{\text{pre}}$ is the baseline measure of ppFEV1.

+ $\alpha$ mean ppFEV1 at baseline in SoC when baseline ppFEV1 is zero^[For the actual model, we centre all of the covariates to improve sampling and all operations are then on the mean centred matrix using a temporary intercept. The $\alpha$ term is recovered as the temporary intercept minus the dot-product of the covariate means and the parameter estimates.]
+	$\beta$ effect of pre treatment ppFEV1 (assumed to be linear)
+	$\gamma_l$ effect of treatment 

and again taking *defer* and *discontinue* as indicator variables of treatment assignment.

### Alternatives

An alternative way in which to analyse the data would be to adopt a linear mixed model including all enrolments and imputing those that have not completed followup at the time of the analysis.

## Priors

The model uses priors:

+ $\alpha \sim \text{Normal}(80, 10)$
+ $\beta \sim \text{Normal}(0, 10)$
+ $\delta_l \sim \text{Normal}(0, 10) \quad l \in \{\text{deferred}, \text{discontinued} \}$ 

The intercept prior is shown in @fig-prior-intercept and reflects the prior on the mean ppFEV1 at baseline.
A mixture of normals may be more appropriate prior model.

```{r, echo = F, eval = T}
#| label: fig-prior-intercept
#| fig-cap: 'Prior on intercept'
#| fig-height: 4
#| fig-width: 4
#| fig-pos: H

d_fig <- data.table(
  x = rnorm(1e6, l[[1]]$cfg$prior$pri_b_0[1], l[[1]]$cfg$prior$pri_b_0[2])
)

ggplot(d_fig, aes(x = x)) +
  geom_density() +
  scale_x_continuous("Intercept") +
  theme_bw() +
  theme(
    legend.position = "bottom",
    legend.box="horizontal",
    strip.text.y.right = element_text(angle = 0,
                                      hjust = 0,
                                      vjust = 0.2,
                                      size = 7),
    axis.ticks = element_blank(),
    strip.text.x.top = element_text(size = 7),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_line(color = "grey",
                                  linewidth = 0.1,
                                  linetype = 1),
    axis.title.y=element_text(size = 7),
    axis.text.y = element_text(size = 7),
    axis.text.x =  element_text(size = 7),
    axis.title.x = element_text(size = 7),
    legend.text = element_text(size = 7)
  ) 
```

# Decision procedures

The decision processes are based on the available complete baseline and followup data.
This approach is simple and offers a transparent interpretation, but it ignores the possibility that accumulating data may shift the posterior.
The decision thresholds and evidential thresholds are shown in @tbl-dec-thresholds.

```{r}
#| echo: FALSE
#| label: tbl-dec-thresholds
#| tbl-pos: H
#| tbl-cap: "Decision threshold parameters"

d_dec_pars <- data.table(
  desc = c("NI", "Inferiority"),
  ref_value = c(l[[1]]$cfg$delta$ni, l[[1]]$cfg$delta$inf),
  threshold = c(l[[1]]$cfg$thresh$ni, l[[1]]$cfg$thresh$inf)
)


gt_tbl <- gt(d_dec_pars) |>
  cols_align(
    columns = 1,
    align = "left"
  ) |>
  cols_align(
    columns = 2:3,
    align = "center"
  )  |>
  cols_label(
    desc = "Decision type",
    ref_value = "Reference value",
    threshold = "Threshold"
  ) |>
  tab_options(
    table.width = pct(60),
    table.font.size = pct(55)) 

gt_tbl 

```

In the current implementation, we evaluate non-inferiority and inferiority at each interim and, if a decision threshold is met, then we will stop recruitment into the relevant arm.
Standard of care remains the reference arm throughout.
This approach is adopted for each interim and the final analysis and is reflected in the current set of results.

The trial setup is such that if the intervention were beneficial, it would reduce the rate of decline for ppFEV1 and we are therefore considering negative non-inferiority margins.
Specifically, if an intervention arm is non-inferior to the reference arm, then the follow up ppFEV1 on the intervention will be reduced by no more than the non-inferiority margin.
Conversely, if the ppFEV1 on the intervention arm falls below the non-inferiority margin with very high probability, then we conclude inferiority.

+ For non-inferiority, we evaluate $\text{Pr}(\delta > \epsilon_{NI}) > \zeta_{NI}$ where $\delta$ is the relevant difference in mean ppFEV1, $\epsilon_{NI}$ and $\zeta_{NI}$ correspond to a non-inferiority margin and an evidential requirement in terms of a probability threshold.
+ For inferiority, we evaluate $\text{Pr}(\delta < \epsilon_{inf}) > \zeta_{inf}$ where $\epsilon_{inf}$ and $\zeta_{inf}$ correspond to a reference value (currently we set $\epsilon_{inf} = \epsilon_{NI}$) and an evidential minimum in terms of a probability threshold.

# Scenarios {#sec-scenarios}

Each scenario adopts a maximum sample size of 600 with interim analyses run when `r paste0(cumsum(l[[1]]$cfg$N)[-length(l[[1]]$cfg$N)], collapse = ", ")` enrolments have occurred.
The treatment effects were specified as differences in mean ppFEV1 at followup.

All scenarios used fixed covariate distributions and effects over the duration of the study. 
Additionally, all simulations used the same reference values and decision thresholds.

```{r, echo = F, eval = T}
#| label: scenario_list
#| code-summary: Scenarios

# Cumulative probability of decisions:

# Traverse the list of simulation results and for each one summarise the 
# cumulative probability of each decision type.

i <- 1
d_scenarios <- data.table()

# For each scenario that was simulated
for(i in 1:length(l)){
  l_cfg <- copy(l[[i]]$cfg)
  
  btrt <- unlist(l_cfg$b_trt)
  
  d_scenarios <- rbind(
    d_scenarios,
    data.table(
      id = i,
      desc = l_cfg$desc,
      delta_2_1 = btrt[2] - btrt[1],
      delta_3_1 = btrt[3] - btrt[1]
    )
  )
}


```

```{r, eval = T}
#| echo: FALSE
#| label: tbl-scenarios
#| tbl-pos: H
#| tbl-cap: "Simulation scenarios"

gt_tbl <- gt(d_scenarios) |>
  cols_width(
    id ~ pct(10),
    desc ~ pct(50),
    delta_2_1 ~ pct(20),
    delta_3_1 ~ pct(20)
  ) |>
  cols_align(
    columns = 1:2,
    align = "left"
  ) |>
  cols_align(
    columns = 3:4,
    align = "center"
  )  |>
  tab_spanner(
    label = md("Difference in mean ppFEV1 relative to SoC"),
    columns = 3:4
  ) |>
  cols_label(
    id = "ID",
    desc = "Scenario",
    delta_2_1 = "Deferred",
    delta_3_1 = "Discontinue"
  ) |>
  tab_options(
    table.width = pct(90),
    container.width = pct(90),
    table.font.size = pct(55)) 

gt_tbl 
```




# Results

## Simulated trial data


### Accrual

```{r, echo = F, eval = T}
#| label: accrual_calc
#| code-summary: Accrual calc


# events per day
lambda <- l[[1]]$cfg$pt_per_day
# ramp up over x months 
rho <- function(t) pmin(t/l[[1]]$cfg$ramp_up_days, 1)

d_acc_t <- rbindlist(pblapply(1:100, cl = 4, FUN=function(ii){
  t0 <- get_enrol_time(sum(l[[1]]$cfg$N), lambda, rho)
  tfu <- t0 +  runif(length(t0), l[[1]]$cfg$fu_days_lwr, l[[1]]$cfg$fu_days_upr)
  data.table(ii, id = 1:sum(l[[1]]$cfg$N), t0, tfu)
}))

d_acc_t <- d_acc_t[, .(t0 = mean(t0), tfu = mean(tfu)), keyby = id]
d_fig_1 <- melt(d_acc_t, id.vars = "id")

d_fig_1[, variable := factor(
  variable, 
  levels = c("t0", "tfu"),
  labels = c("Entry", "Followup"))]
# 
N <- cumsum(l[[1]]$cfg$N)[-length(l[[1]]$cfg$N)]
```


As noted in the data generation section (@sec-data-generation), accrual is assumed to follow a non-homogenous poisson process with linear ramp up over `r l[[1]]$cfg$ramp_up_days` days with around `r l[[1]]$cfg$pt_per_day` enrolments per day (around `r round(365 * l[[1]]$cfg$pt_per_day)` per year).
Follow up is assumed to occur within a window of `r l[[1]]$cfg$fu_days_lwr` to `r l[[1]]$cfg$fu_days_upr` days.

@fig-accrual shows the average accrual and followup for patients within the study assuming no decision rules are triggered and enrolment progresses to the maximum sample size with the initial balanced treatment allocation. 
All scenarios use the same accrual and followup time.
The interim analyses, occurring after fixed number of enrolments, are marked by the dashed lines from which the expected number of participants with followup data and the day at which the analysis is assumed to occur can be seen.
The final analysis is assumed to occur at the maximum followup time (around `r round(max(d_acc_t$tfu)/365, 2)` years).

```{r, echo = F, eval = T}
#| label: fig-accrual
#| fig-cap: 'Average accrual and followup'
#| fig-height: 5
#| fig-width: 5
#| fig-pos: H

# Average observed accrual by trt.



d_tmp <- d_acc_t[N, .(id = .I, analysis_time = t0)]
d_tmp <- d_tmp[
  , .(N = d_acc_t[tfu <= analysis_time, .N]), 
  by = .(id, analysis_time)]

d_fig_2 <- data.table(
  x = rep(0, length(l[[1]]$cfg$N)-1),
  y = N ,
  xend = d_acc_t[id %in% N, t0],
  yend = d_tmp$N
)

ggplot(d_fig_1, aes(x = value, y = id, 
                    group = variable, 
                    col = variable)) +
  geom_step() +
  geom_segment(
    data = d_fig_2,
    aes(x = x, y = y, xend = xend, yend = y), 
    inherit.aes = F, lty = 2, lwd = 0.3) +
  geom_segment(
    data = d_fig_2,
    aes(x = xend, y = y, xend = xend, yend = yend), 
    arrow = arrow(type = "open", length = unit(0.2, "cm")),
    lineend = "round",
    linejoin = "mitre",
    inherit.aes = F, lty = 2, lwd = 0.3) +
  scale_x_continuous("Study day",
                     breaks = seq(0, max(d_acc_t$tfu), by = 100)) +
  scale_y_continuous("Cumulative enrolments",
                     breaks = seq(0, sum(l[[1]]$cfg$N), by = 100)) +
  scale_color_discrete("")+
  theme_minimal() +
  theme(
    legend.position = "bottom",
    # this and the guide call below ensures that you get
    # legends for decision type and trt on different rows
    legend.box="vertical",
    legend.title = element_text(size = 8) ,
    strip.text.y.right = element_text(angle = 0,
                                      hjust = 0,
                                      vjust = 0.2,
                                      size = 7),
    axis.ticks = element_blank(),
    strip.text.x.top = element_text(size = 7),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_line(color = "grey",
                                  linewidth = 0.1,
                                  linetype = 1),
    axis.title.y=element_text(size = 7),
    axis.text.y = element_text(size = 7), 
    axis.text.x = element_text(size = 7), 
    axis.title.x = element_text(size = 7),
    legend.text = element_text(size = 7)
  ) +
  guides(
    colour = guide_legend(nrow = 1),
    linetype = guide_legend(nrow = 1)
  )

  

```

### Participant level ppFEV1

```{r, echo = F, eval = T}
#| label: ppfev1
#| code-summary: Participant ppFEV1


i <- 1
d_ppfev1 <- data.table()

# For each scenario that was simulated
for(i in 1:length(l)){
  
  d_all <- copy(
    l[[i]]$d_all[sim == 1, .(sim, ia, id, trt, y_pre, y_post, y_mis)])
  
  d_all[
    , y_mis := factor(y_mis, 
                      levels = c(0, 1), 
                      labels = c("observed", "missing"))]
  
  l_cfg <- copy(l[[i]]$cfg)
  
  # sim_ex <- sort(sample(1:max(d_all$sim), size = N_example_sims, replace = F))
  # d_all <- d_all[sim %in% sim_ex]
  # 
  d_ppfev1 <- rbind(
    d_ppfev1,
    cbind(scenario = i, desc = l_cfg$desc, d_all)
  )

}


d_ppfev1[, desc := factor(desc, levels = unique(d_ppfev1$desc))]
```

@fig-ppfev1 shows the participant ppFEV1 for the whole cohort in an single simulation for each scenario.
Further calibration of the baseline and followup ppFEV1 may be required.
In the current version, the baseline population mean is `r l[[1]]$cfg$b_0` and the slope is `r l[[1]]$cfg$b_1` ppFEV1 change (in absolute terms) per year.
The unit level variation at baseline is normally distributed around the population mean with standard deviation `r l[[1]]$cfg$u_s0`; the unit level slope has a standard deviation of `r l[[1]]$cfg$u_s1` and the correlation between the two is `r l[[1]]$cfg$u_rho`.
The residual noise is set to have a standard deviation of `r l[[1]]$cfg$b_se`.
The observed correlation between pre and post ppFEV1 is shown in @tbl-cor-pre-post.

```{r, eval = T}
#| echo: FALSE
#| label: tbl-cor-pre-post
#| tbl-cap: 'Correlation between pre and post ppFEV1'
#| tbl-pos: H

d_tbl <- d_ppfev1[, .(cor = cor(y_pre, y_post)), by = .(scenario, desc)]



g_tbl <- d_tbl |> 
  gt() |> 
  cols_align(
    columns = 1:2,
    align = "left"
  )   |>
  cols_label(
    scenario = "ID",
    desc = "Scenario",
    cor = "Correlation between pre and post"
  ) |>
  tab_options(
    table.font.size = pct(55),
    latex.use_longtable = TRUE,
    latex.header_repeat = TRUE 
  ) |>
  fmt_number(columns = cor, decimals = 2, drop_trailing_zeros = F)

g_tbl
```




```{r, echo = F, eval = T}
#| label: fig-ppfev1
#| fig-cap: 'Pre and post values for ppfev1'
#| fig-height: 8
#| fig-width: 7
#| fig-pos: H


d_fig_1 <- copy(d_ppfev1)
d_fig_1 <- melt(
  d_fig_1, measure.vars = c("y_pre", "y_post"), variable.name = "timepoint")
d_fig_1[, timepoint := fifelse(timepoint == "y_pre", "baseline", "followup")]
d_fig_1[, timepoint := factor(timepoint, levels =c("baseline", "followup"))]

d_fig_2 <- d_fig_1[
  y_mis == "observed", .(y_mu = mean(value)), 
  keyby = .(scenario, desc, trt, timepoint)]

ggplot(data = d_fig_1, aes(x = timepoint, y = value, group = id)) +
  geom_line(alpha = 0.5, lwd = 0.2) +
  geom_line(
    data = d_fig_2,
    aes(x = timepoint, y = y_mu, group = trt),
    col = 2, lwd = 0.8, inherit.aes = F
  ) + 
  ggrepel::geom_text_repel(
    data = d_fig_2,
    aes(x = timepoint, y = y_mu, group = trt, label = round(y_mu, 1)),
    box.padding = 5,
    max.overlaps = Inf,
    force        = 0.5,
    nudge_x      = 0.15,
    direction    = "y",
    hjust        = 0,
    segment.size = 0.2,
    inherit.aes = F, col = 2
  ) +
  scale_x_discrete("Timepoint") + 
  scale_y_continuous("Observed ppFEV1", breaks = seq(50, 100, by = 5)) + 
  ggh4x::facet_grid2(
    desc ~ trt, 
    axes = "y",
    labeller = labeller(
      trt = label_both,
      desc = label_wrap_gen(30))) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    # this and the guide call below ensures that you get
    # legends for decision type and trt on different rows
    legend.box="vertical",
    legend.title = element_text(size = 8) ,
    strip.text.y.right = element_text(angle = 0,
                                      hjust = 0,
                                      vjust = 0.2,
                                      size = 7),
    axis.ticks = element_blank(),
    strip.text.x.top = element_text(size = 7),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_line(color = "grey",
                                  linewidth = 0.1,
                                  linetype = 1),
    axis.title.y=element_text(size = 7),
    axis.text.y = element_text(size = 7), 
    axis.text.x = element_text(size = 7), 
    axis.title.x = element_text(size = 7),
    legend.text = element_text(size = 7)
  ) +
  guides(
    colour = guide_legend(nrow = 1),
    linetype = guide_legend(nrow = 1)
  )




  
```

## Example trials

```{r, echo = F}
example_data <- function(id_ex, id_scen = 1){

  # extract the cohort data
  # extract the trial decision
  # extract the posterior at each analysis
  d_all_ex <- copy(l[[id_scen]]$d_all[sim == id_ex])
  d_post_smry_ex <- copy(l[[id_scen]]$d_post_smry_1[sim == id_ex])
  d_pr_dec_ex <- copy(l[[id_scen]]$d_pr_dec[sim == id_ex])
  d_post_all_ex <- copy(l[[id_scen]]$d_post_all[sim == id_ex])
  
  d_post_pars_ex <- copy(d_post_all_ex[, .(ic, b_0, `b[1]`, `b[2]`, `b[3]`, se)])
  setnames(d_post_pars_ex, 
           c("b_0", "b[1]", "b[2]", "b[3]", "se"),
           c("b_0", "b_1", "b_2", "b_3", "se"))
  d_freq_ex <- copy(l[[id_scen]]$d_freq[sim == id_ex])
  d_freq_ex[par == "b[1]", par := "b_1"]
  d_freq_ex[par == "b[2]", par := "b_2"]
  d_freq_ex[par == "b[3]", par := "b_3"]
  
  l_ex <- list(
    d_all_ex = d_all_ex,
    d_post_smry_ex = d_post_smry_ex,
    d_pr_dec_ex = d_pr_dec_ex,
    d_post_all_ex = d_post_all_ex,
    d_post_pars_ex = d_post_pars_ex,
    d_freq_ex = d_freq_ex
  )
}
```

```{r, echo = F}
example_accrual <- function(l_ex, id_scen = 1){

  # Enrolment and followup trajectory

  d_fig_1 <- copy(l_ex$d_all_ex)
  d_fig_2 <- copy(l_ex$d_all_ex)
  d_fig_2  <- d_fig_2[order(tfu)]
  d_fig_2[, id_tmp := 1:.N]
  
  N <- cumsum(l[[id_scen]]$cfg$N)[-length(l[[id_scen]]$cfg$N)]
  d_tmp <- l_ex$d_all_ex[N, .(id = .I, analysis_time = t0)]
  d_tmp <- d_tmp[
    , .(N = l_ex$d_all_ex[tfu <= analysis_time, .N]), 
    by = .(id, analysis_time)]
  
  d_fig_3 <- data.table(
    x = rep(0, length(l[[id_scen]]$cfg$N)-1),
    y = N ,
    xend = l_ex$d_all_ex[id %in% N, t0],
    yend = d_tmp$N
  )


  p <- ggplot(d_fig_1, aes(x = t0, y = id)) +
    geom_step() +
    geom_step(
      data = d_fig_2,
      aes(x = tfu, y = id_tmp), lty = 2, 
      inherit.aes = F) +
    geom_segment(
      data = d_fig_3,
      aes(x = x, y = y, xend = xend, yend = y), 
      inherit.aes = F, lty = 2, lwd = 0.3) +
    geom_segment(
      data = d_fig_3,
      aes(x = xend, y = y, xend = xend, yend = yend), 
      arrow = arrow(type = "open", length = unit(0.2, "cm")),
      lineend = "round",
      linejoin = "mitre",
      inherit.aes = F, lty = 2, lwd = 0.3)  +
    scale_x_continuous(
      "Study day",
      breaks = seq(0, max(d_acc_t$tfu), by = 200)) +
    scale_y_continuous(
      "Cumulative enrolments",
      breaks = seq(0, sum(l[[1]]$cfg$N), by = 100)) +
    scale_color_discrete("") +
    theme_minimal() +
    theme(
      legend.position = "bottom",
      # this and the guide call below ensures that you get
      # legends for decision type and trt on different rows
      legend.box="vertical",
      legend.title = element_text(size = 8) ,
      strip.text.y.right = element_text(angle = 0,
                                        hjust = 0,
                                        vjust = 0.2,
                                        size = 7),
      axis.ticks = element_blank(),
      strip.text.x.top = element_text(size = 7),
      panel.grid.minor = element_blank(),
      panel.grid.major = element_line(color = "grey",
                                    linewidth = 0.1,
                                    linetype = 1),
      axis.title.y=element_text(size = 7),
      axis.text.y = element_text(size = 7), 
      axis.text.x = element_text(size = 7), 
      axis.title.x = element_text(size = 7),
      legend.text = element_text(size = 7),
      plot.title = element_text(size = 10)
    ) +
    guides(
      colour = guide_legend(nrow = 1),
      linetype = guide_legend(nrow = 1)
    ) +
    ggtitle("Plot 1: Accrual")
  
  return(p)
}
```

```{r, echo = F}

example_analysis_sets <- function(l_ex, id_scen = 1){
  # Sample size entering the analysis at each interim by treatment arm 
  
  # Given that there is accrual delay you will find that even after a stopping
  # decision is made, some participants will be found on the arm that was 
  # stopped in the subsequent analysis due to the fact that they were enrolled
  # in the arm but had not reached follow up by the time the decision was made.
  
  # Participants taken into each analysis
  d_fig_1 <- l_ex$d_all_ex[, .(N = .N), keyby = .(ic, ia, trt, y_mis)]
  d_fig_1 <- dcast(d_fig_1, ic + ia + trt ~ y_mis, value.var = "N")
  setnames(d_fig_1, c("0", "1"), c("N_obs", "N_mis"))
  d_fig_1[, N_tot := N_obs + N_mis]
  d_fig_1[, N_obs_c := cumsum(N_obs), keyby = .(trt)]
  
  d_fig_2 <- d_fig_1[!is.na(ia), .(N = sum(N_obs)), keyby = .(ia, trt)]
  d_fig_2[, N_c := cumsum(N), keyby = .(trt)]
  d_fig_2[, `:=`(
    ia = factor(ia),
    trt = factor(trt)
  )]
  
  p <- ggplot(d_fig_2, 
         aes(x = trt, y = N_c)) +
    geom_bar(stat = "identity", width = 0.2) +
    scale_x_discrete("Treatment arm") +
    scale_y_continuous("Participants entering analysis") +
    facet_wrap(~ia, labeller = label_both)+
    theme_minimal() +
    theme(
      legend.position = "bottom",
      # this and the guide call below ensures that you get
      # legends for decision type and trt on different rows
      legend.box="vertical",
      legend.title = element_text(size = 8) ,
      strip.text.y.right = element_text(angle = 0,
                                        hjust = 0,
                                        vjust = 0.2,
                                        size = 7),
      axis.ticks = element_blank(),
      strip.text.x.top = element_text(size = 7),
      panel.grid.minor = element_blank(),
      panel.grid.major = element_line(color = "grey",
                                    linewidth = 0.1,
                                    linetype = 1),
      axis.title.y=element_text(size = 7),
      axis.text.y = element_text(size = 7), 
      axis.text.x = element_text(size = 7), 
      axis.title.x = element_text(size = 7),
      legend.text = element_text(size = 7),
      plot.title = element_text(size = 10)
    ) +
    guides(
      colour = guide_legend(nrow = 1),
      linetype = guide_legend(nrow = 1)
    ) +
    ggtitle("Plot 2: Analysis sets")
  
  return(p)
}

```


```{r, echo = F}

example_inference_cmp <- function(l_ex, id_scen = 1){
  # Bayesian vs frequentist parameters
  d_fig_1 <- copy(l_ex$d_post_pars_ex)
  d_fig_1 <- melt(d_fig_1, id.vars = "ic", variable.name = "par")
  d_fig_1 <- d_fig_1[, .(
    mu = mean(value),
    q_025 = quantile(value, prob = 0.025),
    q_975 = quantile(value, prob = 0.975)), keyby = .(ic, par)]
  d_fig_1[, method := "Bayesian"]
  
  d_fig_2 <- copy(l_ex$d_freq_ex[, .(ic, par, Estimate, `2.5 %`, `97.5 %`)])
  setnames(d_fig_2, c("Estimate", "2.5 %", "97.5 %"), c("mu", "q_025", "q_975"))
  d_fig_2[, method := "Frequentist"]
  
  d_fig_3 <- rbind(d_fig_1, d_fig_2)
  d_fig_3[, method := factor(method, levels = c("Bayesian", "Frequentist"))]
  
  d_fig_3[par == "b_0", par := "intercept"]
  d_fig_3[par == "b_1", par := "y_pre"]
  d_fig_3[par == "b_2", par := "trt_2"]
  d_fig_3[par == "b_3", par := "trt_3"]
  
  d_fig_3[, par := factor(par, levels = c("intercept", "y_pre", "trt_2", "trt_3", "se"))]
  
  p <- ggplot(data = d_fig_3, aes(x = 1, y = mu, group = method, col = method)) +
    geom_linerange(aes(ymin = q_025, ymax = q_975),
                   position = position_dodge2(width = 0.4)) +
    geom_point(position = position_dodge2(width = 0.4)) +
    scale_x_discrete("") +
    scale_y_continuous("Posterior estimate and Cr/Conf interval") +
    facet_grid(par~ic, labeller = label_both, scales = "free_y") +
    theme_minimal() +
    theme(
      legend.position = "bottom",
      # this and the guide call below ensures that you get
      # legends for decision type and trt on different rows
      legend.box="vertical",
      legend.title = element_text(size = 8) ,
      strip.text.y.right = element_text(angle = 0,
                                        hjust = 0,
                                        vjust = 0.2,
                                        size = 7),
      axis.ticks = element_blank(),
      strip.text.x.top = element_text(size = 7),
      panel.grid.minor = element_blank(),
      panel.grid.major = element_line(color = "grey",
                                    linewidth = 0.1,
                                    linetype = 1),
      axis.title.y=element_text(size = 7),
      axis.text.y = element_text(size = 7), 
      axis.text.x = element_text(size = 7), 
      axis.title.x = element_text(size = 7),
      legend.text = element_text(size = 7),
      plot.title = element_text(size = 10)
    ) +
    guides(
      colour = guide_legend(nrow = 1),
      linetype = guide_legend(nrow = 1)
    ) +
    ggtitle("Plot 3: Model parameter estimates")
  
  return(p)
}
```

```{r, echo = F}

example_posterior_inf <- function(l_ex, id_scen = 1){
  
  ni_delta <- l[[id_scen]]$cfg$delta$ni
  # Posterior inference

  d_fig_1 <- copy(l_ex$d_post_smry_ex[par %in% c("mu_1", "mu_2", "mu_3")])
  d_fig_1[, par := factor(par, levels = c("mu_1", "mu_2", "mu_3"), labels = paste0(1:3))]
  
  d_fig_2 <- copy(l_ex$d_post_smry_ex[par %in% c("delta_2_1", "delta_3_1")])
  d_fig_2[, par := factor(par, levels = c("delta_2_1", "delta_3_1"), 
                          labels = c("2 vs 1", "3 vs 1"))]
  
  d_fig_3 <- copy(l_ex$d_pr_dec_ex[par %in% c("delta_2_1", "delta_3_1")])
  d_fig_3[, par := factor(par, levels = c("delta_2_1", "delta_3_1"), 
                          labels = c("2 vs 1", "3 vs 1"))]
  d_fig_3[rule == "inf" & dec == 1, col := "Inferior"]
  d_fig_3[rule == "ni" & dec == 1, col := "NI"]
  d_fig_3[dec == 0, col := "No decision"]
  d_fig_3[, col := factor(col, levels = c("No decision", "NI", "Inferior"))]
  d_fig_3[is.na(col), col := ""]
  
  cols <- c("No decision" = "black", "NI" = "green", "Inferior" = "red")
  
  p1 <- ggplot(d_fig_1, aes(x = par, y = mu)) +
    geom_linerange(aes(ymin = q_025, ymax = q_975)) +
    geom_point() +
    scale_x_discrete("Treatment arm") +
    scale_y_continuous("Posterior summary") +
    facet_wrap(~ic, labeller = label_both) +
    theme_minimal() +
    theme(
      legend.position = "bottom",
      # this and the guide call below ensures that you get
      # legends for decision type and trt on different rows
      legend.box="vertical",
      legend.title = element_text(size = 8) ,
      strip.text.y.right = element_text(angle = 0,
                                        hjust = 0,
                                        vjust = 0.2,
                                        size = 7),
      axis.ticks = element_blank(),
      strip.text.x.top = element_text(size = 7),
      panel.grid.minor = element_blank(),
      panel.grid.major = element_line(color = "grey",
                                    linewidth = 0.1,
                                    linetype = 1),
      axis.title.y=element_text(size = 7),
      axis.text.y = element_text(size = 7), 
      axis.text.x = element_text(size = 7), 
      axis.title.x = element_text(size = 7),
      legend.text = element_text(size = 7)
    ) +
    guides(
      colour = guide_legend(nrow = 1),
      linetype = guide_legend(nrow = 1)
    )
  
  p2 <- ggplot(d_fig_2, aes(x = par, y = mu)) +
    geom_hline(aes(yintercept =  ni_delta), lwd = 0.3, lty = 2 ) +
    geom_linerange(aes(ymin = q_025, ymax = q_975)) +
    geom_point() +
    scale_x_discrete("Comparisons") +
    scale_y_continuous("Posterior summary") +
    facet_wrap(~ic, labeller = label_both) +
    theme_minimal() +
    theme(
      legend.position = "bottom",
      # this and the guide call below ensures that you get
      # legends for decision type and trt on different rows
      legend.box="vertical",
      legend.title = element_text(size = 8) ,
      strip.text.y.right = element_text(angle = 0,
                                        hjust = 0,
                                        vjust = 0.2,
                                        size = 7),
      axis.ticks = element_blank(),
      strip.text.x.top = element_text(size = 7),
      panel.grid.minor = element_blank(),
      panel.grid.major = element_line(color = "grey",
                                    linewidth = 0.1,
                                    linetype = 1),
      axis.title.y=element_text(size = 7),
      axis.text.y = element_text(size = 7), 
      axis.text.x = element_text(size = 7), 
      axis.title.x = element_text(size = 7),
      legend.text = element_text(size = 7)
    ) +
    guides(
      colour = guide_legend(nrow = 1),
      linetype = guide_legend(nrow = 1)
    )
  
  p3 <- ggplot(d_fig_3, aes(x = par)) +
    geom_linerange(aes(ymin = 0, ymax = p, col = col)) +
    scale_x_discrete("Comparisons") +
    scale_y_continuous("Probability", breaks = seq(0, 1, by = 0.5)) +
    scale_color_manual("", values = cols) +
    facet_grid(rule~ic, labeller = label_both) +
    theme_minimal() +
    theme(
      legend.position = "bottom",
      # this and the guide call below ensures that you get
      # legends for decision type and trt on different rows
      legend.box="vertical",
      legend.title = element_text(size = 8) ,
      strip.text.y.right = element_text(angle = 0,
                                        hjust = 0,
                                        vjust = 0.2,
                                        size = 7),
      axis.ticks = element_blank(),
      strip.text.x.top = element_text(size = 7),
      panel.grid.minor = element_blank(),
      panel.grid.major = element_line(color = "grey",
                                    linewidth = 0.1,
                                    linetype = 1),
      axis.title.y=element_text(size = 7),
      axis.text.y = element_text(size = 7), 
      axis.text.x = element_text(size = 7), 
      axis.title.x = element_text(size = 7),
      legend.text = element_text(size = 7)
    ) +
    guides(
      colour = guide_legend(nrow = 1),
      linetype = guide_legend(nrow = 1)
    )
  
  
  return(list(p1 = p1, p2 = p2, p3 = p3))
}
```


### Example 1

```{r, echo = F, eval = T}
#| label: ex_trial_1
#| code-summary: 'Example trial 1 trial data'

id_scen = 1
id_ex <- l[[id_scen]]$cfg$ex_trial_ix[1]
l_ex <- example_data(id_ex, id_scen)
# str(l_ex)
```


```{r, echo = F, eval = T}
#| label: fig-ex1-accrual
#| fig-cap: 'Example trial 1'
#| fig-height: 7
#| fig-width: 7
#| fig-pos: H

layout <- "
AAABBB
AAABBB
######
#CCCC#
#CCCC#
#CCCC#
#CCCC#
"

p1 <- example_accrual(l_ex, id_scen)
p2 <- example_analysis_sets(l_ex, id_scen)
p3 <- example_inference_cmp(l_ex, id_scen)

suppressWarnings(print(p1 + p2 + p3 + 
  plot_layout(design = layout) ))
```


```{r, echo = F, eval = T}
#| label: fig-ex1-post-result
#| fig-cap: 'Example trial 1 posterior summary and decision probabilities'
#| fig-height: 8
#| fig-width: 7
#| fig-pos: H

l_p <- example_posterior_inf(l_ex, id_scen)
suppressWarnings(print(l_p$p1 / l_p$p2 / l_p$p3))
```



### Example 2

```{r, echo = F, eval = T}
#| label: ex_trial_2
#| code-summary: 'Example trial 2 trial data'


id_scen = 2
id_ex <- l[[id_scen]]$cfg$ex_trial_ix[1]
l_ex <- example_data(id_ex, id_scen)
```


```{r, echo = F, eval = T}
#| label: fig-ex2-accrual
#| fig-cap: 'Example trial 2'
#| fig-height: 7
#| fig-width: 7
#| fig-pos: H

layout <- "
AAABBB
AAABBB
######
#CCCC#
#CCCC#
#CCCC#
#CCCC#
"

p1 <- example_accrual(l_ex, id_scen)
p2 <- example_analysis_sets(l_ex, id_scen)
p3 <- example_inference_cmp(l_ex, id_scen)

suppressWarnings(print(p1 + p2 + p3 + 
  plot_layout(design = layout) ))
```


```{r, echo = F, eval = T}
#| label: fig-ex2-post-result
#| fig-cap: 'Example trial 2 posterior summary and decision probabilities'
#| fig-height: 8
#| fig-width: 7
#| fig-pos: H

l_p <- example_posterior_inf(l_ex, id_scen)
suppressWarnings(print(l_p$p1 / l_p$p2 / l_p$p3))
```



### Example 3

```{r, echo = F, eval = T}
#| label: ex_trial_3
#| code-summary: 'Example trial 3 trial data'


id_scen = 3
id_ex <- l[[id_scen]]$cfg$ex_trial_ix[1]
l_ex <- example_data(id_ex, id_scen)
```


```{r, echo = F, eval = T}
#| label: fig-ex3-accrual
#| fig-cap: 'Example trial 3 posterior summary and decision probabilities'
#| fig-height: 8
#| fig-width: 7
#| fig-pos: H

layout <- "
AAABBB
AAABBB
######
#CCCC#
#CCCC#
#CCCC#
#CCCC#
"

p1 <- example_accrual(l_ex, id_scen)
p2 <- example_analysis_sets(l_ex, id_scen)
p3 <- example_inference_cmp(l_ex, id_scen)

suppressWarnings(print(p1 + p2 + p3 + 
  plot_layout(design = layout) ))
```


```{r, echo = F, eval = T}
#| label: fig-ex3-post-result
#| fig-cap: 'Example trial 3 inferential framework comparison'
#| fig-height: 7
#| fig-width: 7
#| fig-pos: H

l_p <- example_posterior_inf(l_ex, id_scen)
suppressWarnings(print(l_p$p1 / l_p$p2 / l_p$p3))
```

## Probability of triggering decisions

@tbl-cprob-decision provides the cumulative probability of superiority by scenario with the probability of declaring inferiority in parentheses.
@fig-cprob-decision gives a visual representation of the same data; each of the columns of plots give the results for a specific difference in means and each row is aligns with a scenario.

```{r, echo = F, eval = T}
#| label: cum_prob_dec
#| code-summary: Cumulative probability of each decision type

# Cumulative probability of decisions:

# Traverse the list of simulation results and for each one summarise the 
# cumulative probability of each decision type.

i <- 1
d_cprob_dec <- data.table()

# For each scenario that was simulated
for(i in 1:length(l)){
  
  # extract the decision matrix - sim, analysis, quantity, domain level decision
  d_dec_1 <- copy(l[[i]]$d_pr_dec[par %in% c("delta_2_1", "delta_3_1")])
  # config for scenario
  l_cfg <- copy(l[[i]]$cfg)
  
  # number of enrolments at each interim (interim sample size sequence)
  d_N <- data.table(ic = seq_along(l_cfg$N), N = cumsum(l_cfg$N))
  
  
  # compute the cumulative instances of a decision being made by sim, each 
  # decision type and by parameter
  d_dec_1[, cdec := as.integer(cumsum(dec)>0), keyby = .(sim, rule, par)]
  d_dec_1[, cdec := nafill(cdec, type = "locf"), keyby = .(sim, rule, par)]
  d_dec_1[, cdec := as.logical(cdec)]
  
  d_dec_1 <- merge(d_dec_1, d_N, by = "ic")
  # cumulative proportion for which each decision quantity has been met by 
  # analysis and domain
  d_dec_1 <- d_dec_1[, .(pr_val = mean(cdec)), keyby = .(ic, N, rule, par)]
  
  
  d_cprob_dec <- rbind(
    d_cprob_dec,
    cbind(scenario = i, desc = l_cfg$desc, d_dec_1)
  )

}

```


```{r, eval = T}
#| echo: FALSE
#| label: tbl-cprob-decision
#| tbl-cap: 'Cumulative probability of decision for each enrolment cohort'
#| tbl-pos: H



d_tbl_1_cur <- copy(d_cprob_dec)
d_tbl_1_cur <- dcast(
  d_tbl_1_cur, scenario + desc + par ~ rule + N, value.var = "pr_val")

d_tbl_1_cur[par == "delta_2_1", par := "Deferred"]
d_tbl_1_cur[par == "delta_3_1", par := "Discontinued"]

# d_tbl_2_cur <- copy(d_cprob_dec_ref)
# d_tbl_2_cur <- dcast(
#   d_tbl_2_cur, scenario + desc + par ~ rule + N, value.var = "pr_val")
# 
# d_tbl_2_cur[par == "rd_2_1", par := "Deferred"]
# d_tbl_2_cur[par == "rd_3_1", par := "Discontinued"]
# 
# setnames(d_tbl_2_cur, "inf_600", "ref_inf_600")
# setnames(d_tbl_2_cur, "ni_600", "ref_ni_600")

d_b_trt <- data.table()

for(i in 1:length(l)){
  l_cfg <- copy(l[[i]]$cfg)
  btrt <- unlist(l_cfg$b_trt)
  
  d_tmp <- data.table(scenario = i, 
                      par = c("Deferred", "Discontinued"), 
                      delta = c(btrt[2]-btrt[1], btrt[3]-btrt[1]))
  d_b_trt <- rbind(d_b_trt, d_tmp)
}

d_tbl_1_cur <- merge(d_tbl_1_cur, d_b_trt, by = c("scenario", "par"))
# d_tbl_1_cur <- merge(d_tbl_1_cur, d_tbl_2_cur, by = c(
#   "scenario", "desc", "par"
# ))


setcolorder(d_tbl_1_cur, c("scenario", "desc", "par", "delta"))
setorderv(d_tbl_1_cur, cols = c("scenario"))

d_tbl_1_cur <- d_tbl_1_cur[, .SD, .SDcols = !c("scenario")]

g_tbl <- d_tbl_1_cur |> 
  gt(groupname_col = "desc") |> 
  gt::text_transform(
    locations = cells_row_groups(),
    fn = function(x) {
      lapply(x, function(x) {
        gt::md(paste0("*", x, "*"))
      })
    }
  ) |>
  cols_align(
    columns = 1:2,
    align = "left"
  )  |> 
  cols_align(
    columns = 3:ncol(d_tbl_1_cur),
    align = "center"
  )  |> 
  cols_merge(
    columns = c("ni_400", "inf_400"
                ),
    pattern = "<<{1}>><< ({2})>>"
  )   |> 
  cols_merge(
    columns = c("ni_500", "inf_500"
                ),
    pattern = "<<{1}>><< ({2})>>"
  ) |> 
  cols_merge(
    columns = c("ni_600", "inf_600"
                ),
    pattern = "<<{1}>><< ({2})>>"
  )   |>
  cols_width(
    starts_with("ni") ~ px(90)
  ) |>
  tab_spanner(
    label = md("Participants having reached primary endpoint"),
    columns = 4:ncol(d_tbl_1_cur)
  )  |>
  cols_label(
    delta = "Difference in means at 12 month",
    par = "",
    ni_400 = html("400"),
    ni_500 = html("500"),
    ni_600 = html("600")
  ) |>
  tab_options(
    table.font.size = pct(55),
    latex.use_longtable = TRUE,
    latex.header_repeat = TRUE 
  ) |>
  fmt_number(decimals = 2, drop_trailing_zeros = F)

g_tbl
```


{{< pagebreak >}}

```{r, echo = F, eval = T}
#| label: fig-cprob-decision
#| fig-cap: 'Cumulative probability of decision based on enrolments with follow up at each interim'
#| fig-height: 7
#| fig-width: 7
#| fig-pos: H


d_fig_1 <- copy(d_cprob_dec)

d_fig_1 <- merge(
  d_fig_1, 
  melt(d_scenarios[, .(id, delta_2_1, delta_3_1)], id.vars = "id", value.name = "delta") ,
  by.x = c("scenario", "par"),
  by.y = c("id", "variable")
)

d_fig_1[, rule := factor(
  rule, levels = c("ni", "inf"), labels = c("NI", "Inferiority"))]


d_fig_1[, par := factor(
  par, levels = c("delta_2_1", "delta_3_1"), labels = c("Deferred", "Discontinued"))]

d_fig_1[, group := paste0(par, " - ", rule)]
d_fig_1[, lab := paste0("Delta = ", delta)]

d_fig_1[, lab := factor(
  lab, levels = paste0("Delta = ", sort(unique(d_fig_1$delta))) )]


ggplot(d_fig_1, aes(x = N, y = pr_val, group = group , 
                    col = par, lty =  rule)) +
  geom_line(lwd = 0.25) +
  scale_linetype_manual("Decision type", 
                        values = c("solid", "dashed")) +
  scale_color_manual("Treatment stratergy", 
                     values = c("#E66100", "#5D3A9B")) +
  scale_x_continuous("Enrolment") +
  scale_y_continuous("Pr(decision)", breaks = seq(0, 1, by = 0.2)) +
  facet_grid2(
    desc ~ lab ,
    labeller = labeller(desc = label_wrap_gen(30))) + 
  theme_minimal() +
  theme(
    legend.position = "bottom",
    # this and the guide call below ensures that you get
    # legends for decision type and trt on different rows
    legend.box="vertical",
    legend.title = element_text(size = 8) ,
    strip.text.y.right = element_text(angle = 0,
                                      hjust = 0,
                                      vjust = 0.2,
                                      size = 7),
    axis.ticks = element_blank(),
    strip.text.x.top = element_text(size = 7),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_line(color = "grey",
                                  linewidth = 0.1,
                                  linetype = 1),
    axis.title.y=element_text(size = 7),
    axis.text.y = element_text(size = 7), 
    axis.text.x = element_text(size = 7), 
    axis.title.x = element_text(size = 7),
    legend.text = element_text(size = 7)
  ) +
  guides(
    colour = guide_legend(nrow = 1),
    linetype = guide_legend(nrow = 1)
  )


```


{{< pagebreak >}}

## Sample size

@tbl-n-1 shows the expected number of participants on each treatment for a stopping decision (either NI or inferiority) to occur.

```{r, echo = F, eval = T}
#| label: sample_size_1
#| code-summary: Compute expected sample size


i <- 1
d_N_by_rand <- data.table()

for(i in 1:length(l)){
  
  # config for scenario
  l_cfg <- copy(l[[i]]$cfg)
  
  N_analysis <- length(l_cfg$N)
  N_trt <- length(l_cfg$b_trt)
  # 
  d_grid <- CJ(
    sim = 1:l_cfg$nsim,
    ic = 1:N_analysis,
    trt = 1:N_trt
  )
    
  # pick up the baseline obs only, i.e. when the number enrolled
  d_all <- copy(l[[i]]$d_all[, ])
  
  d_all <- merge(
    d_grid,
    d_all[, .(.N), keyby = .(sim, ic, trt)],
    by = c("sim", "ic", "trt"),
    all.x = T
  )
  
  # some arms stop and so there is no suubsequent enrolment
  d_all[is.na(N), N := 0]
  d_all[, N_cmtv := cumsum(N), keyby = .(sim, trt)]
  
  d_N_by_rand <- rbind(
    d_N_by_rand,
    cbind(
      scenario = i, desc = l_cfg$desc, 
      d_all
    )
  )
  
}
```

```{r, eval = T}
#| echo: FALSE
#| label: tbl-n-1
#| tbl-cap: 'Expected number of participants **enrolled** by treatment group for each scenario'
#| tbl-pos: H

# DONT assume that all arms ran to the final interim. The result is just an
# artefact of imputation. Nevertheless it gives the true sample size by arm.
d_N_trt <- d_N_by_rand[, .SD[.N], keyby = .(scenario, desc, sim, trt)]
d_N_tot <- d_N_trt[, .(N_cmtv = sum(N_cmtv)), keyby = .(scenario, desc, sim) ]

# add in total sample size
d_tbl_1_cur <- rbind(
  d_N_trt[, .(N_mu = mean(N_cmtv), N_sd = sd(N_cmtv)), keyby = .(scenario, desc, trt)],
  d_N_tot[, .(trt = "all", N_mu = mean(N_cmtv), N_sd = sd(N_cmtv)), keyby = .(scenario, desc)]
)

d_tbl_1_cur[trt == 1, trt := "SoC"]
d_tbl_1_cur[trt == 2, trt := "Deferred"]
d_tbl_1_cur[trt == 3, trt := "Discontinued"]

# we are only interested in Deferred vs soc and Discontinued vs soc
d_b_trt <- data.table()

for(i in 1:length(l)){
  l_cfg <- copy(l[[i]]$cfg)
  btrt <- unlist(l_cfg$b_trt)
  d_tmp <- data.table(
    scenario = i, 
    trt = c("Deferred", "Discontinued"), 
    delta = c(btrt[2]-btrt[1], btrt[3]-btrt[1]))
  d_b_trt <- rbind(d_b_trt, d_tmp)
}

d_tbl_1_cur <- merge(
  d_tbl_1_cur, 
  d_b_trt, 
  by = c("scenario", "trt"),
  all.x = T)

d_tbl_1_cur <- dcast(
  d_tbl_1_cur, 
  scenario + desc ~ trt , 
  value.var = list("N_mu", "N_sd", "delta"))

d_tbl_1_cur[, `:=`(delta_SoC = NULL, delta_all = NULL)]

setcolorder(d_tbl_1_cur, c("scenario", "desc", "delta_Deferred", "delta_Discontinued"))

d_tbl_1_cur <- d_tbl_1_cur[order(scenario, desc)]
d_tbl_1_cur <- d_tbl_1_cur[, .SD, .SDcols = !c("scenario")]



g_tbl <- d_tbl_1_cur |> 
  gt(groupname_col = "desc")  |>
  fmt_number(
    columns = starts_with("N_"),
    decimals = 0, drop_trailing_zeros = TRUE) |>
  fmt_number(
    columns = starts_with("delta"),
    decimals = 2, drop_trailing_zeros = TRUE) |> 
  tab_spanner(
    label = md("Difference in means (ref SoC)"),
    columns = starts_with("delta"),
  ) |>
  tab_spanner(
    label = md("Sample size, mean (sd)"),
    columns =  starts_with("N_mu")
  ) |>
  cols_align(
    columns = starts_with("delta"),
    align = "center"
  ) |>
  cols_align(
    columns = starts_with("N_mu"),
    align = "center"
  )  |>
  cols_merge(
    columns = c("N_mu_Deferred", "N_sd_Deferred"
                ),
    pattern = "<<{1}>><< ({2})>>"
  ) |>
  cols_merge(
    columns = c("N_mu_Discontinued", "N_sd_Discontinued"
                ),
    pattern = "<<{1}>><< ({2})>>"
  ) |>
  cols_merge(
    columns = c("N_mu_SoC", "N_sd_SoC"
                ),
    pattern = "<<{1}>><< ({2})>>"
  ) |>
  cols_merge(
    columns = c("N_mu_all", "N_sd_all"
                ),
    pattern = "<<{1}>><< ({2})>>"
  ) |>
  cols_label(
    delta_Deferred = "Deferred",
    delta_Discontinued = "Discontinued",
    N_mu_Deferred = "Deferred",
    N_mu_Discontinued = "Discontinued",
    N_mu_SoC = "SoC",
    N_mu_all = "Total"
  ) |>
  tab_options(
    # table.width = pct(100),
    table.font.size = pct(55)
  ) 


g_tbl
```






{{< pagebreak >}}
## Parameter estimation

@tbl-post-delta and @fig-expected-delta show the expected value of the posterior means (and 95% interval) for the treatment effects by scenario.

```{r, echo = F, eval = T}
#| label: post-means
#| code-summary: Distributions of posterior means (unconditional)

# Distribution of posterior means for parameters of interest.

# Some simulated trials will have stopped prior to the maximum sample size and
# these will have NA for their posterior means. If you were to summarise these 
# posterior means, they would be conditional on the trial having 'survived' 
# until the relevant interim. This means that you have missing data at later 
# interims, which creates a selection bias in that your selection of sims at any
# given interim are not a random sample, but rather a sample conditioned on the 
# stopping rules. 

# If you do not account for this in some way then a summary can be either 
# optimistic or pessimistic depending on how the stopping rules interact 
# with the data. Here we try to account for this missingness by imputing the 
# missing posterior means with locf within each simulation.
# Note that this is really only a partial 'fix' to get a sense of whether 
# our estimates is representative of the parameter values we used to simulate
# the data.

i <- 1
d_post_1 <- data.table()

for(i in 1:length(l)){
  
  # config for scenario
  l_cfg <- copy(l[[i]]$cfg)
  
  b_trt <- unlist(l_cfg$b_trt)
  
  # params
  d_pars <- copy(l[[i]]$d_post_smry_1)
  d_pars <- d_pars[par %in% c("delta_2_1", "delta_3_1"), .(sim, ic, par, mu)]
  d_pars[, mu :=  nafill(mu, type = "locf"), keyby = .(sim, par)]
  
  # interim looks
  d_N <- data.table(ic = seq_along(l_cfg$N), N = cumsum(l_cfg$N))
  d_pars <- base::merge(d_pars, d_N, by = "ic")
  
  d_pars[par == "delta_2_1", delta_tru := b_trt[2] - b_trt[1]]
  d_pars[par == "delta_3_1", delta_tru := b_trt[3] - b_trt[1]]
  
  d_post_1 <- rbind(
    d_post_1,
    cbind(
      scenario = i, desc = l_cfg$desc, 
      d_pars
      )
  )

}

d_post_1 <- d_post_1[order(scenario, desc, sim, ic)]





```

```{r, eval = T}
#| echo: FALSE
#| label: tbl-post-delta
#| tbl-cap: 'Parameter estimation - difference in mean ppFEV1 (expectation of posterior means and 95% interval)'
#| tbl-pos: H

d_tbl_1_cur <- d_post_1[,
                 .(mu = mean(mu),
                   q_025 = quantile(mu, prob = 0.025),
                   q_975 = quantile(mu, prob = 0.975)), 
                 keyby = .(scenario, desc, ic, par, delta_tru, N)]
# setorderv(d_fig, cols = "scenario", order = -1L)
d_tbl_1_cur[, desc := factor(desc, levels = unique(d_post_1$desc))]

d_tbl_1_cur <- dcast(
  d_tbl_1_cur, 
  scenario + desc + par + delta_tru ~ N, value.var = list("mu", "q_025", "q_975"))

ci_names <- function(x = 500){
  paste0(c("mu_","q_025_", "q_975_"), x)
}
setcolorder(
  d_tbl_1_cur, 
  c("scenario", "desc",  "par", "delta_tru",
    ci_names(400), ci_names(500), ci_names(600)))

d_tbl_1_cur[par == "delta_2_1", par := "Deferred"]
d_tbl_1_cur[par == "delta_3_1", par := "Discontinued"]


d_tbl_1_cur <- d_tbl_1_cur[, .SD, .SDcols = !c("scenario")]


g_tbl <- d_tbl_1_cur |>
  gt(groupname_col = "desc")  |>
  cols_align(
    columns = 1:2,
    align = "left"
  ) |>
  cols_align(
    columns = 3:ncol(d_tbl_1_cur),
    align = "right"
  )   |> 
  cols_merge(
    columns = c("par", "delta_tru"),
    pattern = "<<{1}>><< ({2})>>"
  )  |> 
  cols_merge(
    columns = c("mu_400", "q_025_400", "q_975_400"),
    pattern = "<<{1}>><< ({2}, {3})>>"
  )  |> 
  cols_merge(
    columns = c("mu_500", "q_025_500", "q_975_500"),
    pattern = "<<{1}>><< ({2}, {3})>>"
  )  |> 
  cols_merge(
    columns = c("mu_600", "q_025_600", "q_975_600"),
    pattern = "<<{1}>><< ({2}, {3})>>"
  )  |> 
  cols_label(
    par = "Comparison (true difference in means)",
    mu_400 = "400",
    mu_500 = "500",
    mu_600 = "600"
  )  |>
  tab_spanner(
    label = html("Difference in means (expectation of posterior means and 95 pct interval)"),
    columns = 2:ncol(d_tbl_1_cur)
    ) |>
  tab_options(
    table.font.size = pct(55),
    latex.use_longtable = TRUE,
    latex.header_repeat = TRUE 
    ) |>
   fmt_number(decimals = 2, drop_trailing_zeros = F)

g_tbl

```

```{r, eval = T, echo = F}
#| label: fig-expected-delta
#| fig-cap: 'Distribution of posterior means for treatment effects by interim and simulation scenario'
#| fig-height: 8
#| fig-width: 7
#| fig-pos: H

d_fig <- copy(d_post_1)
d_fig[, desc := factor(desc, levels = unique(d_fig$desc))]
d_fig[, N := factor(N)]

d_fig[par == "delta_2_1", par := paste0("Deferred")]
d_fig[par == "delta_3_1", par := paste0("Discontinued")]

ggplot(data = d_fig, aes(x = N, y = mu, col = par)) +
  geom_boxplot(outlier.size = 0.1, lwd = 0.3) +
  ggh4x::facet_grid2(desc ~ . , 
             labeller = labeller(
               desc = label_wrap_gen(25)
               # ,
               # par = label_wrap_gen(15)
               ), 
             scales = "free",
             axes = "y",
             independent = "y")  +
  scale_color_manual("", values = c("#E66100", "#5D3A9B")) +
  scale_x_discrete("") +
  scale_y_continuous("Difference in means") +
  theme_bw() +
  theme(
    legend.position = "bottom",
        text = element_text(size = 6),
        strip.text.y.right = element_text(angle = 0,
                                      hjust = 0,
                                      vjust = 0.2,
                                      size = 6),
        strip.text.x = element_text(angle = 0, size = 6),
        axis.ticks = element_blank(),
        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),
        axis.text.y = element_text(size = 6),
        panel.grid.minor = element_blank(),
        panel.grid.major = element_line(color = "grey",
                                  linewidth = 0.1,
                                  linetype = 1))


```

## Observed ppFEV1

@tbl-obs-ppFev1 shows the mean observed ppFEV1 (and differences) by scenario and treatment arm.

```{r, echo = F, eval = T}
#| label: empirical-risk
#| code-summary: Summaries of empirical ppFEV1

i <- 1
d_ppfev1_obs <- data.table()

for(i in 1:length(l)){
  
  # config for scenario
  l_cfg <- copy(l[[i]]$cfg)
  
  # interim looks
  d_enrolment <- data.table(
    ic = seq_along(l_cfg$N), N_enrol = cumsum(l_cfg$N))

  # observed data
  d_all <- copy(l[[i]]$d_all)
  d_all <- base::merge(d_all, d_enrolment , by = "ic")
  d_all <- d_all[y_mis == 0, .(mu_obs = mean(y_post)), keyby = .(sim, trt)]
  d_all <- d_all[, .(mu_obs = mean(mu_obs)), keyby = .(trt)]
  
  d_all <- dcast(d_all, 1 ~ trt, value.var = "mu_obs")
  
  d_all[, delta_2_1 := `2` - `1`]
  d_all[, delta_3_1 := `3` - `1`]
  
  d_ppfev1_obs <- rbind(
    d_ppfev1_obs, 
    cbind(
      scenario = i, 
      desc = l_cfg$desc, 
      d_all
      )
  )
  
}

d_ppfev1_obs[, `.`:= NULL]
setnames(d_ppfev1_obs, paste0(1:3), paste0("mu_obs_", 1:3))


```


```{r}
#| echo: FALSE
#| label: tbl-obs-ppFev1
#| tbl-cap: 'Observed mean ppFEV1 (and differences) by scenario, treatment and strata'
#| tbl-pos: H

d_tbl_1_cur <- copy(d_ppfev1_obs)
# setorderv(d_fig, cols = "scenario", order = -1L)
d_tbl_1_cur[, desc := factor(desc, levels = unique(d_post_1$desc))]

d_tbl_1_cur[, `:=`(scenario = NULL)]

g_tbl <- d_tbl_1_cur |>
  gt(groupname_col = "desc")  |>
  cols_align(
    columns = 1:3,
    align = "left"
  ) |>
  cols_align(
    columns = 4:ncol(d_tbl_1_cur),
    align = "right"
  )   |> 
  cols_label(
    mu_obs_1 = "SoC",
    mu_obs_2 = "Deferred",
    mu_obs_3 = "Discontinued",
    delta_2_1 = "Deferred",
    delta_3_1 = "Discontinued"
  )  |>
  tab_spanner(
    label = html("Mean ppFev1 at 12 months"),
    columns = starts_with("mu_obs")
    ) |>
  tab_spanner(
    label = html("Difference in means"),
    columns = starts_with("delta_")
    ) |>
  tab_options(
    table.font.size = pct(55),
    latex.use_longtable = TRUE,
    latex.header_repeat = TRUE 
    ) |>
   fmt_number(decimals = 2, drop_trailing_zeros = F)

g_tbl

```


{{< pagebreak >}}
## Repository status {.unlisted .unnumbered}

\footnotesize
```{r}
#| echo: false
repo <- repository(path = ".")
summary(repo)
```
\normalsize

{{< pagebreak >}}
## Stan models

\footnotesize
```{r}
#| class-output: stan
#| echo: false

cat(readLines(paste0(prefix_stan, "/sim02-v01.stan")), sep = "\n")
```
\normalsize


{{< pagebreak >}}
## References

<!-- Needs to have a citation for this to work otherwise you will get the old \end{CSLReferences} error  -->


